import safetensors
import safetensors.torch
import torch
import collections
#In Chameleon hf Models, we do not have decoder parameters
#For 7b:
with safetensors.safe_open("/home/zlhu/data2/zlhu/chameleon-7b_hf_add_decoder/model-00003-of-00003.safetensors",framework="pt",device=7) as f:
   tensor_dict = {key: f.get_tensor(key) for key in f.keys()}
#For 30b:


state_dict=torch.load("/home/zlhu/data2/zlhu/Anole-7b-v0.1/tokenizer/vqgan.ckpt")["state_dict"]
print(len(tensor_dict))
only_decoder_dict=collections.OrderedDict()
for k in state_dict.keys():
    if 'decoder' in k:
        new_key='model.vqmodel.'+k
        tensor_dict[new_key]=state_dict[k]
meta_data={"format":"pt"}
safetensors.torch.save_file(tensor_dict,'/home/zlhu/data2/zlhu/chameleon-7b_hf_add_decoder/model-00003-of-00003.safetensors',metadata=meta_data)
with safetensors.safe_open("/home/zlhu/data2/zlhu/chameleon-7b_hf_add_decoder/model-00003-of-00003.safetensors",framework="pt") as f:
    meta=f.metadata()
    print(meta)
print(len(tensor_dict))

#Then add to model.safetensors.index.json
'''
    "model.vqmodel.decoder.conv_in.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.conv_in.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.conv_out.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.conv_out.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.k.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.k.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.norm.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.norm.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.proj_out.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.proj_out.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.q.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.q.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.v.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.attn_1.v.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_1.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_1.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_1.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_1.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_1.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_1.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_1.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_1.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_2.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_2.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_2.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_2.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_2.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_2.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_2.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.mid.block_2.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.norm_out.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.norm_out.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.0.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.0.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.0.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.0.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.0.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.0.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.0.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.0.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.1.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.1.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.1.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.1.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.1.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.1.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.1.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.1.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.2.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.2.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.2.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.2.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.2.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.2.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.2.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.0.block.2.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.nin_shortcut.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.nin_shortcut.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.0.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.1.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.1.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.1.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.1.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.1.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.1.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.1.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.1.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.2.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.2.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.2.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.2.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.2.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.2.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.2.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.block.2.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.upsample.conv.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.1.upsample.conv.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.0.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.0.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.0.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.0.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.0.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.0.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.0.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.0.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.1.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.1.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.1.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.1.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.1.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.1.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.1.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.1.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.2.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.2.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.2.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.2.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.2.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.2.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.2.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.block.2.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.upsample.conv.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.2.upsample.conv.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.nin_shortcut.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.nin_shortcut.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.0.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.1.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.1.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.1.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.1.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.1.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.1.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.1.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.1.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.2.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.2.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.2.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.2.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.2.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.2.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.2.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.block.2.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.upsample.conv.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.3.upsample.conv.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.0.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.0.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.0.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.0.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.0.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.0.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.0.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.0.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.1.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.1.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.1.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.1.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.1.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.1.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.1.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.1.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.2.conv1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.2.conv1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.2.conv2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.2.conv2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.2.norm1.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.2.norm1.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.2.norm2.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.block.2.norm2.weight": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.upsample.conv.bias": "model-00003-of-00003.safetensors",
    "model.vqmodel.decoder.up.4.upsample.conv.weight": "model-00003-of-00003.safetensors",
'''

        